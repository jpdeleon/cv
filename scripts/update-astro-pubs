#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
If to run locally, first get NASA ADS token from 
https://ui.adsabs.harvard.edu/user/settings/token
save it to a file called `~/.ads/dev_key`
then run from base
$ python scripts/update-astro-pubs

If to run on GitHub Actions, set the token as a secret called ADS_DEV_KEY
"""
import os
import json
import importlib.util
from operator import itemgetter

import ads
# ads.config.token = 'my token'

# Get the current directory of the script
here = os.path.dirname(os.path.abspath(__file__))
# Import the 'utf8totex' module
spec = importlib.util.spec_from_file_location(
    "utf8totex", os.path.join(here, "utf8totex.py")
)
utf8totex = importlib.util.module_from_spec(spec)
spec.loader.exec_module(utf8totex)

# query using real name and aliases
real_name = ["de Leon, J. P."]
aliases = ["Leon, J. P. D.", "Leon, Jerome de", "Pitogo de Leon, Jerome"]
# exclude papers by namesake with asteroid in abstract
search_query = 'aff:"University of Tokyo" database:astronomy -abs:asteroid -abs:comet'
# search_query += "year:2014-2025"
stop_words_in_title = ["author correction", "erratum", "correction to:"]

def get_papers(author):
    # Perform an ADS search query to retrieve information about the author's papers
    papers = list(
        ads.SearchQuery(
            q=search_query,
            author=author,
            fl=[
                "id",
                "title",
                "author",
                "doi",
                "year",
                "pubdate",
                "pub",
                "volume",
                "page",
                "identifier",
                "doctype",
                "citation_count",
                "bibcode",
            ],
            max_pages=100,
        )
    )
    unique_entries = set()  # Set to store unique combinations of formatted_titles and stop_word
    dicts = [] # List to store non-duplicate entries
    for paper in papers:
        # Process and filter arxiv id
        if paper.identifier is None:
            continue
        aid = [
            ":".join(t.split(":")[1:])
            for t in paper.identifier
            if t.startswith("arXiv:")
        ]
        for t in paper.identifier:
            if len(t.split(".")) != 2:
                continue
            try:
                list(map(int, t.split(".")))
            except ValueError:
                pass
            else:
                aid.append(t)
        try:
            page = int(paper.page[0])
        except (ValueError, TypeError):
            page = None
            if paper.page is not None and paper.page[0].startswith("arXiv:"):
                aid.append(":".join(paper.page[0].split(":")[1:]))
        try:
            formatted_authors = list(map(utf8totex.utf8totex, paper.author))
            formatted_titles = utf8totex.utf8totex(paper.title[0].replace(" &amp; ", " & ").replace("<SUB>", "_").replace("</SUB>", "_"))
        except Exception as e:
            print(e)
            formatted_authors = list(paper.author)
            formatted_titles = paper.title[0].replace(" &amp; ", " & ").replace("<SUB>", "_").replace("</SUB>", "_")
        # Create a dictionary with relevant paper information
        include_flag = [stop_word not in formatted_titles.lower() for stop_word in stop_words_in_title]
        if all(include_flag):
            entry = dict(
                doctype=paper.doctype,
                authors=formatted_authors,
                year=paper.year,
                pubdate=paper.pubdate,
                doi=paper.doi[0] if paper.doi is not None else None,
                title=formatted_titles,
                pub=paper.pub,
                volume=paper.volume,
                page=page,
                arxiv=aid[0] if len(aid) else None,
                citations=(
                    paper.citation_count if paper.citation_count is not None else 0
                ),
                url="https://ui.adsabs.harvard.edu/abs/" + paper.bibcode,
            )
            # Check if the entry is unique
            if formatted_titles not in unique_entries:
                dicts.append(entry)
                unique_entries.add(formatted_titles)
        else:
            print(f"Ignoring the following entry because the title contains '{stop_words_in_title}':\n{formatted_titles}")

    return sorted(dicts, key=itemgetter("pubdate"), reverse=True)


if __name__ == "__main__":
    papers = []
    authors = real_name + aliases
    for author in authors:
        paper = get_papers(author)
        papers.extend(paper)
    papers = sorted(papers, key=itemgetter("pubdate"), reverse=True)
    
    fout = "data/pubs.json"
    with open(fout, "w") as f:
        json.dump(papers, f, sort_keys=True, indent=2, separators=(",", ": "))
    print("Saved: ", fout)
